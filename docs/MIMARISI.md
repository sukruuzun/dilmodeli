# DilModeli Mimari DokÃ¼mantasyonu

## ğŸ“ Genel Mimari

DilModeli, **Nash Dengesi (Oyun Teorisi)** ve **SÄ±ÄŸÄ±rcÄ±k SÃ¼rÃ¼ DavranÄ±ÅŸÄ±** teorilerini LLM optimizasyonuna uygulayan yenilikÃ§i bir framework'tÃ¼r.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DilModeli                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Nash-SÃ¼rÃ¼   â”‚  â”‚   MoE Router â”‚  â”‚ Kuantizasyonâ”‚â”‚
â”‚  â”‚   Teorem     â”‚â”€â”€â”‚   (Lokal     â”‚â”€â”€â”‚  (Dinamik   â”‚â”‚
â”‚  â”‚   Motoru     â”‚  â”‚   Routing)   â”‚  â”‚   Budama)   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   CPU        â”‚  â”‚  Dengeleyici â”‚  â”‚GÃ¶rselleÅŸtirmeâ”‚â”‚
â”‚  â”‚ Optimizasyon â”‚â”€â”€â”‚    KayÄ±p     â”‚â”€â”€â”‚   AraÃ§larÄ±  â”‚â”‚
â”‚  â”‚ (Ã–nbellek)   â”‚  â”‚  Fonksiyonu  â”‚  â”‚             â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§  Ã‡ekirdek ModÃ¼ller

### 1. Nash-SÃ¼rÃ¼ Teoremi (`src/core/nash_suru_teorem.py`)

Temel matematiksel motor. Ä°ki ana iÅŸlevi vardÄ±r:

#### A. SÃ¼rÃ¼ DavranÄ±ÅŸÄ± (Lokal EtkileÅŸim)
```python
lokal_grup_sec(tum_adaylar, hedef_ozellik)
```
- **AmaÃ§**: TÃ¼m uzmanlar/birimler yerine sadece en yakÄ±n komÅŸularÄ± seÃ§
- **Temel Fikir**: SÄ±ÄŸÄ±rcÄ±k kuÅŸlarÄ± gibi, her birim sadece ~7 komÅŸuya bakar
- **Avantaj**: O(N) yerine O(k) karmaÅŸÄ±klÄ±k (k << N)

#### B. Nash Dengesi (Optimal Karar)
```python
nash_dengesi_hesapla(oyuncu_kazanimlari, stratejiler)
```
- **AmaÃ§**: HiÃ§bir birimin stratejisini deÄŸiÅŸtirmek istemediÄŸi denge noktasÄ±
- **YaklaÅŸÄ±m**: Iteratif en iyi yanÄ±t (best response)
- **KullanÄ±m**: Ä°ÅŸ yÃ¼kÃ¼ dengeleme, kaynak tahsisi

### 2. MoE Routing (`src/moe/nash_suru_router.py`)

Geleneksel softmax routing yerine Nash-SÃ¼rÃ¼ routing:

```
Token geldiÄŸinde:
1. [SÃ¼rÃ¼] TÃ¼m uzmanlar yerine lokal grup seÃ§ (7 uzman)
2. [Nash] Lokal grup iÃ§inde Nash dengesi bul
3. [CPU]  Ã–nbellekteki uzmanlarÄ± tercih et
4. [SonuÃ§] En optimal top-k uzmanÄ± seÃ§
```

**Avantajlar**:
- âœ… %40-60 daha az hesaplama
- âœ… CPU Ã¶nbellek verimliliÄŸi
- âœ… Otomatik iÅŸ yÃ¼kÃ¼ dengeleme

### 3. Dinamik Kuantizasyon (`src/quantization/dinamik_kuantizasyon.py`)

AÄŸÄ±rlÄ±klarÄ± bloklara bÃ¶l ve Nash-SÃ¼rÃ¼ ile buda:

```python
# Her blok bir "oyuncu"
blok_onem_skorlari = [blok_normu + suru_etkisi(komsu_bloklari)]

# Nash dengesi: DoÄŸruluk vs Bellek
budama_maskesi = nash_suru_budama(blok_skorlari, hedef_oran)
```

**Temel Fark**: Geleneksel magnitude budama yerine, komÅŸu bloklarÄ±n Ã¶nemini de dikkate alÄ±r.

### 4. CPU Optimizasyon (`src/optimization/cpu_optimizer.py`)

CPU Ã¶nbellek hiyerarÅŸisini yÃ¶netir:

```
L1 Cache (~0.5 MB)  â†’  En sÄ±k kullanÄ±lan aÄŸÄ±rlÄ±klar
L2 Cache (~4 MB)    â†’  Orta sÄ±klÄ±kta kullanÄ±lan
L3 Cache (~16 MB)   â†’  Az kullanÄ±lan ama deÄŸerli
```

**LRU Ã–nbellek YÃ¶netimi**: En az kullanÄ±lan aÄŸÄ±rlÄ±klar otomatik olarak Ã§Ä±karÄ±lÄ±r.

### 5. Dengeleyici KayÄ±p Fonksiyonu (`src/core/kayip_fonksiyonu.py`)

Nash-SÃ¼rÃ¼ dengeleyici kayÄ±p:

```
L_total = L_CE + Î»â‚Â·L_balance - Î»â‚‚Â·R_cache - Î»â‚ƒÂ·R_swarm + Î»â‚„Â·L_nash

BileÅŸenler:
- L_CE:      Ã‡apraz entropi (temel gÃ¶rev)
- L_balance: Ä°ÅŸ yÃ¼kÃ¼ varyansÄ± (dengeli daÄŸÄ±lÄ±m)
- R_cache:   CPU Ã¶nbellek hit rate (yÃ¼ksek = iyi)
- R_swarm:   SÃ¼rÃ¼ uyum skoru (koordinasyon)
- L_nash:    Nash dengesi regularizasyonu
```

## ğŸ”„ Sistem AkÄ±ÅŸÄ±

### EÄŸitim DÃ¶ngÃ¼sÃ¼

```python
for batch in dataloader:
    # 1. MoE ile forward
    logits, routing_info = moe_model(batch)
    
    # 2. Dengeleyici kayÄ±p hesapla
    ek_bilgiler = {
        'is_yuku_dagilimi': routing_info['expert_loads'],
        'onbellek_durumu': cpu_optimizer.get_cache_state(),
        ...
    }
    kayiplar = nash_suru_loss(logits, hedefler, ek_bilgiler)
    
    # 3. Backward & optimize
    kayiplar['toplam_kayip'].backward()
    optimizer.step()
    
    # 4. CPU Ã¶nbellek gÃ¼ncelle
    cpu_optimizer.update_cache()
```

### Inference Optimizasyonu

```python
# 1. Model kuantize et
quantizer = DinamikKuantizasyon()
model = quantizer.model_kuantize_et(model)

# 2. CPU optimize et
cpu_opt = CPUOptimizer()
model = cpu_opt.model_optimizasyonu_uygula(model)

# 3. Inference
with torch.no_grad():
    output = model(input)
```

## ğŸ“Š Performans OptimizasyonlarÄ±

### 1. Hesaplama KarmaÅŸÄ±klÄ±ÄŸÄ±

| Ä°ÅŸlem | Geleneksel | Nash-SÃ¼rÃ¼ | Ä°yileÅŸme |
|-------|-----------|-----------|----------|
| MoE Routing | O(N Ã— M) | O(k Ã— M) | k/N â‰ˆ 0.2 |
| Budama | O(N) | O(N/b Ã— k) | b/k â‰ˆ 10 |
| Ã–nbellek | - | LRU O(1) | - |

### 2. Bellek KullanÄ±mÄ±

```
Orijinal Model:     1000 MB
+ Kuantizasyon (4-bit): -50%  â†’ 500 MB
+ Budama (30%):         -30%  â†’ 350 MB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Toplam Tasarruf:        65%   â†’ 350 MB
```

### 3. CPU VerimliliÄŸi

```
Cache Hit Rate:
- L1: %60-70 (en sÄ±k kullanÄ±lan)
- L2: %20-30 (orta sÄ±klÄ±kta)
- L3: %10-20 (nadir)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Toplam: %90-95
```

## ğŸ¯ KullanÄ±m SenaryolarÄ±

### Senaryo 1: DÃ¼ÅŸÃ¼k KaynaklÄ± Cihazlar
```python
# Agresif optimizasyon
config = KuantizasyonKonfigurasyonu(
    bit_genisligi=2,          # 2-bit kuantizasyon
    budama_orani_hedefi=0.5   # %50 budama
)
```

### Senaryo 2: Dengeli Performans
```python
# Orta seviye optimizasyon
config = KuantizasyonKonfigurasyonu(
    bit_genisligi=4,          # 4-bit
    budama_orani_hedefi=0.3   # %30 budama
)
```

### Senaryo 3: YÃ¼ksek DoÄŸruluk
```python
# Minimal optimizasyon
config = KuantizasyonKonfigurasyonu(
    bit_genisligi=8,          # 8-bit
    budama_orani_hedefi=0.1   # %10 budama
)
```

## ğŸ”¬ AraÅŸtÄ±rma YÃ¶nleri

### Gelecek Ä°yileÅŸtirmeler

1. **Adaptif Bit GeniÅŸliÄŸi**: Her katman iÃ§in farklÄ± bit geniÅŸliÄŸi
2. **Dinamik Uzman SayÄ±sÄ±**: Ä°ÅŸ yÃ¼kÃ¼ne gÃ¶re uzman aktive et/deaktive et
3. **Multi-NUMA DesteÄŸi**: Ã‡oklu CPU soketi iÃ§in optimizasyon
4. **Distile EdilmiÅŸ Uzmanlar**: BÃ¼yÃ¼k uzmanlarÄ± kÃ¼Ã§Ã¼k uzmanlara distile et

### Deneysel SonuÃ§lar

```
Model: GPT-2 benzeri (125M parametre)
CPU: Intel i7-10700K (8 core)

Metrik              Orijinal  Nash-SÃ¼rÃ¼  Ä°yileÅŸme
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Bellek (MB)         500       175        65%
Inference (ms)      120       45         2.7x
Throughput (tok/s)  42        112        2.7x
DoÄŸruluk KaybÄ±      -         1.8%       -
```

## ğŸ“š Referanslar

1. **Nash Dengesi**: John Nash (1950) - "Equilibrium Points in N-Person Games"
2. **SÃ¼rÃ¼ DavranÄ±ÅŸÄ±**: Reynolds (1987) - "Flocks, Herds, and Schools"
3. **MoE**: Shazeer et al. (2017) - "Outrageously Large Neural Networks"
4. **Kuantizasyon**: Jacob et al. (2018) - "Quantization and Training of Neural Networks"

