# ğŸš€ Google Colab Setup Guide

## ğŸ““ How to Run Nash-Swarm Tests in Google Colab

### Method 1: Direct Python Script (Easiest!)

**Step 1:** Open [Google Colab](https://colab.research.google.com/)

**Step 2:** Create a new notebook

**Step 3:** Copy-paste this code into cells:

---

### ğŸ¦… GPT-2 Demo (5-10 minutes)

```python
# Cell 1: Setup
!git clone https://github.com/sukruuzun/dilmodeli.git
%cd dilmodeli
!pip install -q torch transformers datasets numpy

print("âœ… Setup complete!")
```

```python
# Cell 2: Run Test
!python tests/compare_simple_quantization.py
```

**Expected Output:**
```
Method          Loss    Î” Loss    Compression    Size
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Baseline        5.414   -         0%             475 MB
Uniform 4-bit   6.689   +23.56%   87.5%          59 MB
Nash-Swarm      5.421   +0.12%    90.7%          44 MB  âœ…

ğŸ¯ Nash-Swarm is 196Ã— better!
```

---

### ğŸ¦™ LLaMA Demo (30-60 minutes, GPU recommended)

```python
# Cell 1: Setup (Enable GPU!)
# Runtime â†’ Change runtime type â†’ GPU (T4)
!nvidia-smi  # Check GPU

!git clone https://github.com/sukruuzun/dilmodeli.git
%cd dilmodeli
!pip install -q torch transformers datasets numpy

print("âœ… GPU setup complete!")
```

```python
# Cell 2: Run LLaMA Test
!python tests/test_llama_quantization.py
```

**Note:** Free Colab has 12-16 GB RAM + GPU, enough for TinyLlama 1.1B!

---

### âš¡ Speed Benchmark (Optional)

```python
# Run speed test
!python tests/benchmark_speed.py
```

---

## ğŸ¨ Customize Your Test

### Test Different Models

```python
# Edit model name before running
!sed -i 's/model_name = "gpt2"/model_name = "gpt2-medium"/' tests/compare_simple_quantization.py
!python tests/compare_simple_quantization.py
```

### Change Sample Size

```python
# Edit sample size (default: 30 for LLaMA, 50 for GPT-2)
!sed -i 's/text_samples\[:30\]/text_samples[:10]/' tests/test_llama_quantization.py
!python tests/test_llama_quantization.py
```

---

## ğŸ“Š Save Your Results

```python
# Save output to file
!python tests/compare_simple_quantization.py > my_results.txt

# Download results
from google.colab import files
files.download('my_results.txt')
```

---

## ğŸ› Troubleshooting

### "Out of Memory" Error
- Enable GPU: Runtime â†’ Change runtime type â†’ GPU
- Reduce sample size (see "Change Sample Size" above)
- Use smaller model (gpt2 instead of gpt2-medium)

### "Module not found" Error
- Re-run Cell 1 (Setup)
- Make sure you're in `/content/dilmodeli` directory

### Slow Execution
- Enable GPU if testing LLaMA
- GPT-2 runs fine on CPU (~5-10 mins)

---

## ğŸ¯ Quick Links

- ğŸ“„ **Paper:** [ArXiv:XXXX.XXXXX](https://arxiv.org/abs/XXXX.XXXXX)
- ğŸ’» **GitHub:** [dilmodeli](https://github.com/sukruuzun/dilmodeli)
- ğŸ“§ **Contact:** sukru@yes.tools

---

## ğŸ“ Creating a Persistent Notebook

Want to save your Colab notebook for later?

1. Follow steps above to create cells
2. File â†’ Save a copy in Drive
3. Share the link!

**Template notebook coming soon!**

